import streamlit as st
from core.services.books.book_service import BookService
from core.services.gpt.gpt_service import GptService
from core.config.gpt import GptConfig
from core.utils.common_utils import load_json_file
from core.config import BOOKS_DIR
from core.utils.gpt_utils import count_tokens

def show():
    st.title("âš™ï¸ Asystent AI")

    # ZaÅ‚aduj ksiÄ…Å¼kÄ™ z kontekstu sesji
    selected_book = st.session_state.get("selected_book", None)
    if not selected_book:
        st.warning("Najpierw wybierz ksiÄ…Å¼kÄ™ we wÅ‚aÅ›ciwym widoku.")
        return

    # UtwÃ³rz domyÅ›lny obiekt konfiguracji GPT
    gpt_config = GptConfig(model="gpt-4o-mini", max_tokens=128000, temperature=0.7, output_percentage=0.2, prompt_percentage=0.8)

    st.subheader(f"KsiÄ…Å¼ka: {selected_book.title}")
    st.markdown("Wygeneruj opracowanie ksiÄ…Å¼ki za pomocÄ… AI.")

    if GptService.is_summarizable(selected_book.content, gpt_config):
        # Koszt streszczenia
        token_count = count_tokens(selected_book.content)
        cost = token_count * 0.000002 / 1000
        st.markdown(f"**Koszt streszczenia: {cost:.2f} PLN\tTokeny: {token_count}**")
        if st.button("ğŸ“„ Wygeneruj streszczenie"):
            with st.spinner("GenerujÄ™ streszczenie..."):
                gpt_service = GptService(api_key=st.secrets["OPENAI_API_KEY"])
                summary = gpt_service.summarize_text(gpt_config, selected_book.content)
                st.session_state["summary"] = summary
                st.success("Streszczenie wygenerowane!")

        if st.session_state.get("summary"):
            st.markdown(f"### ğŸ“˜ Streszczenie {selected_book.title}:")
            st.text_area("Wynik:", st.session_state["summary"], height=400)
    else:
        st.error("ğŸ“ KsiÄ…Å¼ka zbyt dÅ‚uga, aby jÄ… streÅ›ciÄ‡ przy obecnej konfiguracji.")
        token_count = count_tokens(selected_book.content)
        st.markdown(f"**Tokeny w ksiÄ…Å¼ce: {token_count}\tMaksymalna liczba tokenÃ³w do przetworzenia: {gpt_config.prompt_percentage * gpt_config.max_tokens}**")
